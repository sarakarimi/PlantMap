[project]
name = "pretrain-clip"
version = "0.1.0"
description = "uv environment for running CLIP finetuning, with or without model checkpoints. If a checkpoint is provided, the model will be loaded from the checkpoint and finetuned on the specified dataset. If no checkpoint is provided, the model will be loaded from the Hugging Face model hub and finetuned on the specified dataset."
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
  "accelerate>=1.2.1",
  "datasets>=3.2.0",
  "huggingface-hub>=0.27.0",
  "hydra-core>=1.3.2",
  "lightning>=2.4.0",
  "lightning-lite>=1.8.6",
  "scikit-learn>=1.6.0",
  "torch>=2.3.0",
  "torchaudio>=2.5.1",
  "torchvision>=0.20.1",
  "tqdm>=4.67.1",
  "transformers>=4.47.0",
]

[tool.uv.sources]
torch = { index = "pytorch" }

[[tool.uv.index]]
name = "pytorch"
url = "https://download.pytorch.org/whl/cu121"
explicit = true
